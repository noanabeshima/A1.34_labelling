{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "acts, toks = torch.load('state.pt', weights_only=False)\n",
    "\n",
    "acts, toks = acts[:10000], toks[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:22:11,720\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "/home/noa/.miniconda/envs/tokre/lib/python3.11/site-packages/tinymodel/tokenization/tokenization.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  neo_tok_ids_to_ts = torch.load(f\"{current_dir}/neo_tok_ids_to_ts.pt\")\n",
      "/home/noa/.miniconda/envs/tokre/lib/python3.11/site-packages/tinymodel/tokenization/tokenization.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ts_tok_ids_to_neo = torch.load(f\"{current_dir}/ts_tok_ids_to_neo.pt\")\n"
     ]
    }
   ],
   "source": [
    "# from noa_tools import reload_module\n",
    "# reload_module('tokre')\n",
    "import tokre\n",
    "from tokre import SynthFeat\n",
    "import tinymodel\n",
    "\n",
    "\n",
    "tokre.setup(workspace='workspace', tokenizer=tinymodel.tokenizer)\n",
    "\n",
    "\n",
    "synth = SynthFeat(r'''\n",
    "valid_last_tok = (?<![re `[.,?!\"';:\\#$^&*]` search=True])|(?<=[re `'(\\S){1,7}`])\n",
    "space_tok = [re ` [\\S]+`][valid_last_tok]\n",
    "eos_tok = ([re `[.!?]` search=True]|[flex `[.!?,\"',;:()]*`])\n",
    "nospace_tok = [re `[\\S]+`][valid_last_tok]\n",
    "capitalized_nospace_tok = [re `[A-Z].*`]\n",
    "\n",
    "nospace_word = (?<=\\n|\\[BEGIN\\]|[eos_tok])[nospace_tok]{1,}(?=[space_tok]|[eos_tok])\n",
    "space_word = ([space_tok][nospace_tok]*(?=[space_tok]|[eos_tok])| o'clock)\n",
    "\n",
    "word = [nospace_word] | [space_word]\n",
    "\n",
    "( named)[named_name=[word]].{,30}[var_variant_prefix [named_name]]\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating parallel matchers\n",
      "created parallel matchers\n",
      "created batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=7634)\u001b[0m Calling ray.init() again after it has already been called.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-10 14:22:20,647 E 7298 7322] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-09-10_14-22-09_638881_7193 is over 95% full, available space: 18706923520; capacity: 982819848192. Object creation will fail if spilling is required.\n",
      "\u001b[36m(ParallelModule pid=7634)\u001b[0m /home/noa/.miniconda/envs/tokre/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(ParallelModule pid=7634)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(ParallelModule pid=7634)\u001b[0m   neo_tok_ids_to_ts = torch.load(f\"{current_dir}/neo_tok_ids_to_ts.pt\")\n",
      "\u001b[36m(ParallelModule pid=7634)\u001b[0m   ts_tok_ids_to_neo = torch.load(f\"{current_dir}/ts_tok_ids_to_neo.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ParallelModule pid=7633)\u001b[0m initializing parallel module\n",
      "\u001b[36m(ParallelModule pid=7633)\u001b[0m initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=7636)\u001b[0m Calling ray.init() again after it has already been called.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-10 14:22:30,657 E 7298 7322] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-09-10_14-22-09_638881_7193 is over 95% full, available space: 18702430208; capacity: 982819848192. Object creation will fail if spilling is required.\n",
      "\u001b[36m(ParallelModule pid=7637)\u001b[0m /home/noa/.miniconda/envs/tokre/lib/python3.11/site-packages/tinymodel/tokenization/tokenization.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(ParallelModule pid=7637)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ParallelModule pid=7637)\u001b[0m   neo_tok_ids_to_ts = torch.load(f\"{current_dir}/neo_tok_ids_to_ts.pt\")\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ParallelModule pid=7637)\u001b[0m   ts_tok_ids_to_neo = torch.load(f\"{current_dir}/ts_tok_ids_to_neo.pt\")\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-10 14:22:40,668 E 7298 7322] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-09-10_14-22-09_638881_7193 is over 95% full, available space: 18699329536; capacity: 982819848192. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-10 14:22:50,683 E 7298 7322] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-09-10_14-22-09_638881_7193 is over 95% full, available space: 18699325440; capacity: 982819848192. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "synth_mask = synth.get_mask(toks, n_matchers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysvelte\n",
    "\n",
    "pysvelte.WeightedDocs(acts=(synth_mask).tolist(), docs=toks.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
